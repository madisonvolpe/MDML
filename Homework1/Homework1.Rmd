---
title: "MDML Homework1"
author: "Madison Volpe and Andrea Hassler"
date: "9/15/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(tidyverse)
library(lubridate)
library(geosphere)
```

# 2

## A) Download 2013 NYC Taxi Data and Read Csvs

```{r, eval=FALSE}
trips <- read_csv("trip_data_8.csv")
fares <- read_csv("trip_fare_8.csv")
```

## B) Create new datasets based on 08/15/2018

```{r, eval=FALSE}
# Filtering on 08/15/2018
trips <- filter(trips, as.Date(trips$pickup_datetime) == "2013-08-15")
fares <- filter(fares, as.Date(fares$pickup_datetime) == "2013-08-15")

# Writing csvs
write_csv(trips, "trips_hw_1.csv")
write_csv(fares, "fares_hw_1.csv")
``` 

```{r, message=FALSE}
# Read in csvs 
trips <- read_csv("trips_hw_1.csv")
fares <- read_csv("fares_hw_1.csv") 
```

## C) Clean both the ‘trips’ and ‘fares’ tibbles using your best judgment. Document your cleaning steps and assumptions.

## Trips 

### Examining trip_distance in trips tibble

```{r}
summary(trips$trip_distance)

# Check trips over 50 miles
nrow(trips[trips$trip_distance > 50, ])

# Filter between 0 and 50 miles
trips <- trips %>%
  filter(trip_distance > 0 & trip_distance < 50) %>%
  arrange(trip_distance)
```

The documentation for the dataset describes trip distance as distance measured by the taximeter in miles. The summary command reveals that the range of trip_distance in the dataset is from 0 miles to 5,043,318 miles. When we subset the trips tibble on trips that have a trip_distance greater than 50, we see that there are only 49 observations out of 473,544 that have trip_distance greater than 50 miles. Therefore, we made the decision to restrict observations in trips to trip_distances greater than 0, but less than 50 miles. 

```{r}
summary(trips$trip_distance)
```

We now see that the range of our trip_distance variable is from .01 miles to 48 miles, which seems more reasonable. 

### Examining passenger_count

```{r}
summary(trips$passenger_count)

# Filter out 0 passenger counts
trips <- trips %>%
  filter(passenger_count > 0) 

summary(trips$passenger_count)
```

According to NYC.gov, the legal amount of passengers for taxis in NYC is between four or five depending on the size of the vehicle. Also small children are allowed to sit on laps in the back seat, therefore a max of six passengers is justifiable. When we initially ran the summary command, we saw trips that had a passenger count of zero. Therefore, we decided to filter out those trips. After performing this operation, the range of the passenger_count variable was from 1 to 6 passenegers.

### Examining trip_time_in_secs in trips tibble

```{r}
summary(trips$trip_time_in_secs)

# Add new column to trips tibble that is an alternative measure of trip time in secs
trips <- mutate(trips, trip_time_in_secs_2 = as.duration(dropoff_datetime - pickup_datetime))

# Test if the two columns have the exact same values 
all(trips$trip_time_in_secs == as.integer(trips$trip_time_in_secs_2))
```

The documentation for the dataset describes the trip_time_in_secs variable as the trip time measured in seconds by the taximeter. However, it also states that sometimes this variable is recorded in minutes. Therefore, the documentation notes that this variable is unreliable and informs us that a more reliable measure of trip time is obtained by subtracting pickup_datetime from dropoff_datetime.

The initial summary of trip_time_in_secs shows that the range for this value is from -10 to 22080. We then computed the more "accurate" measure of trip time by subtracting pickup_datetime from dropoff_datetime, and we named this variable trip_time_in_secs_2. We used the all command to check if the two columns, trip_time_in_secs and trip_time_in_secs2, are the same for all values. The FALSE informed us that they are not. 

```{r}
# Check difference between the values in the two trip time measures
trips <- mutate(trips, diff = abs(dseconds(trip_time_in_secs) - trip_time_in_secs_2))
trips <- arrange(trips, desc(diff)) 
head(trips$diff, 20)

# Filter to only have trips that differ in these two variables by less than 1 min
trips <- filter(trips, diff < dminutes(1))
head(trips$diff, 20) 
range(trips$diff) #difference ranging from 0 to 57 seconds! 

# Drop irrelevant columns
trips <- select(trips, -trip_time_in_secs_2, -diff) 

summary(trips$trip_time_in_secs)

# Filter to remove negative trip times that are less than 60 seconds (1 min)
trips <- trips %>%
  filter(trip_time_in_secs >= 60 )

summary(trips$trip_time_in_secs)
```

Next, we created a new variable, diff, which takes the difference from the trip_time_in_secs variable, which is native to the dataset and can be an inaccurate measure of trip time, and trip_time_in_secs2 variable, constructed as a more valid measure of trip time. We then filtered to include only the trips that differed between these two measures by less than one minute (60 seconds). 

After doing this, the summary of trip_time_in_secs still revealed unlikely numbers, such as a -10 second trip time. However, the max value of 22,080 seconds, or 6.1 hours, did seem more likely. The mean of 13.8 minutes (830 seconds) seems likely as well. Ultimately, we decided to keep trips that only have trip_time_in_secs greater than or equal to 60 seconds (1 minute). This was checked by running summary on trip_time_in_secs to reveal the new min value of 60 seconds. 

### Examining unrealistic speeds and distances

The dataset documentation mentions cases of unrealistic speeds and distances in the dataset. First, we checked for unrealistic speeds by converting trip time from seconds to hours and then calculating average speed by dividing trip distance by trip time in hours.

```{r}
# Add average speed
trips <- mutate(trips, avg_speed = trip_distance/(trip_time_in_secs/3600))
# Top average speeds
head(sort(trips$avg_speed, decreasing = T))
# Filter out trip speeds greater than 100mph
trips <- filter(trips, avg_speed < 100)
summary(trips$avg_speed)
```
We filtered out average speeds over 100mph. We left the very low average trip speeds, since these make sense under heavy traffic conditions. Next, we checked unrealistic distances, defined as trip distances that are shorter than the straight-line distance between the pickup location and dropoff location, given in latitude and longitude coordinates. For this, we wanted to use the geoshere package and calculate distance using the Haversine formula. Unfortunately, this process was too memory-intensive to compute for this many observations given limited computing power. The code below shows the removal of impossible longitude and latitude values, as well as the code we would have used to remove unrealistic distances.

```{r}
# Check number of unrealistic longitude and latitude values
nrow(trips[trips$pickup_longitude < -90 | trips$pickup_longitude > 90, ])
nrow(trips[trips$dropoff_longitude < -90 | trips$dropoff_longitude > 90, ])
nrow(trips[trips$pickup_latitude < -180 | trips$pickup_latitude > 180, ])
nrow(trips[trips$dropoff_latitude < -180 | trips$dropoff_latitude > 180, ])

# Filter out unrealistic coordinates
trips <- filter(trips, 
                pickup_longitude >= -90 & pickup_longitude <= 90,
                dropoff_longitude >= -90 & dropoff_longitude <= 90,
                pickup_latitude >= -180 & pickup_latitude <= 180,
                dropoff_latitude >= -180 & dropoff_latitude <=180)

# Compute straight-line distances in miles
# trips <- mutate(trips, 
#                 straight_dist = distm(x = cbind(pickup_longitude, pickup_latitude),
#                                       y = cbind(dropoff_longitude, dropoff_latitude), 
#                                       fun = distHaversine))
```

## Fares

### Examining payment_type 

```{r}
# Examine the different values for payment type 
unique(fares$payment_type)

# Filter only on cash (CSH) and and credit (CRD) payment types 
fares <- fares %>%
  filter(payment_type %in% c("CSH", "CRD"))

unique(fares$payment_type)
```

We decided to examine payment_type and we limited payment_type to only cash and credit payments. In the dataset documentation, these are listed as the only possible forms of payment. 

### Examining fare_amount 

```{r}
# Summary on fare_amount 
summary(fares$fare_amount)

# Examining outliers, negative values, and values greater than 500
nrow(fares[fares$fare_amount < 0, ])
sum(fares$total_amount[fares$fare_amount < 0] < 0)
fares$fare_amount[fares$fare_amount > 500]

# Filter for fare amounts greater than 2.50 
fares <- fares %>%
  filter(fare_amount >= 2.50)

# Reobserving fare_amount
summary(fares$fare_amount)
```

The fare_amount, which represents the meter fare in USD, has a range of -460.00 dollars to 955.00 dollars.There are 126 observations with negative values for fare_amount that also extend to negative total_amount. Furthermore, we observed 4 observations with fare_amount greater than 500 dollars. We decided to drop any fare_amount less than \$2.50 because $2.50 is the minimum initial charge listed by the NYC Taxi & Limousine Commission, but we decided to keep the fare_amount values over 500 dollars, which may not be unrealistic for longer trips out of the city.

### Examining other charges and amounts

```{r}
# Summary for other variables in the fares tibble
summary(fares$surcharge)
summary(fares$mta_tax)
summary(fares$tip_amount)
summary(fares$tolls_amount)
summary(fares$total_amount)

# Check that total_amount is true total
fares <- mutate(fares, calc_total = 
                  fare_amount + surcharge + mta_tax + tip_amount + tolls_amount)
all(fares$total_amount == fares$calc_total)
fares <- mutate(fares, diff = round(abs(total_amount - calc_total), 3))

# Remove differences larger than $1
head(sort(fares$diff, decreasing = T))
nrow(fares[fares$diff > 0, ])
fares <- filter(fares, diff == 0)
summary(fares$diff)

# Remove extra variables
fares <- select(fares, -calc_total, -diff)
```

We examined the remaining variables, which all looked reasonable. We then removed any observations whose total_amount did not match the calculated total from the variables (18 cases).

## D) [10 pts] Join the ‘trips’ and ‘fares’ tibbles together into a tibble called ‘taxi_data.’ This joined tibble should have one row for each trip, and should have complete fare information (you may have to deal with duplicates and missing values that arise from the join).

### Initial Cleaning 

```{r}
# Create unique ID variables for trips and fares tibbles 
trips$UID <- paste(trips$medallion, trips$hack_license, trips$pickup_datetime, sep = "_")
fares$UID <- paste(fares$medallion, fares$hack_license, fares$pickup_datetime, sep = "_")

# Checking to see if the unique ID repeats one time only. In other words, if it refers to one trip and the fares associated with the one trip 

trips %>% count(UID)%>%filter(n>1) #works for trips 
length(unique(trips$UID)) == nrow(trips) #also see if true 

fares %>% count(UID)%>%filter(n>1) #does not work for fares 
length(unique(fares$UID)) == nrow(fares) #we can see that there are duplicates! 

# Remove duplicate values
trips <- distinct(trips)
fares <- distinct(fares)
```

The preliminary checks reveal that the unique identifier in trips does correspond to just one trip. However, the unique identifier for fares may correspond to two or more trips. The directions asked for a dataset that has one row for each trip along with complete fare information. In this case, our final tibble should have 457,005 rows to correspond to each unique trip from the trips tibble. 

```{r}
# Convert pickup_datetime in fares to POSIX so that it could be joined with trips
fares$pickup_datetime <- as.POSIXct(fares$pickup_datetime)

# Left join trips and fares to save all rows from the trips tibble 
taxi_data <- trips %>% left_join(fares)

# Does one  UID still correspond to just one trip ?
taxi_data %>% count(UID)%>%filter(n>1)
``` 

An initial left join to create the taxi_data dataset leaves us with 457,085 observations. This is more rows than the initial trips dataset of 457,005. With the trips dataset, we had already found out that each UID accounted for one trip. When reusing the code from above, we see that there are 80 observations that are duplicated (have the same UID).

```{r}
# Anti join to see if there are rows in trips that do not have corresponding fares associated
trips %>% anti_join(fares)
```

There are 1,011 rows in trips that do not have corresponding fares. 

```{r}
# Delete "duplicate" rows in the fares tibble by keeping the fare with highest total amount
fares <- fares %>% arrange(desc(total_amount)) %>% distinct(medallion, hack_license, pickup_datetime, .keep_all = TRUE)
```

```{r}
# Inner join trips and fares
taxi_data <- inner_join(trips,fares)

# Check to see that the number of rows resulting from the inner join plus the nrow from the anti join equals the nrow of trips tibble
nrow(taxi_data) + nrow(trips %>% anti_join(fares)) == nrow(trips)  
```

```{r}
length(unique(taxi_data$UID)) == nrow(taxi_data) #one row for each trip test 
sum(is.na(taxi_data[,16:22])) #complete fare information for each trip test. 
```

We checked to see that the number of unique UIDs in taxi_data is equal to the number of rows, which implies that each row represents only one trip. We also checked to see that the join produced complete fare information for each trip.

## E) For each taxicab, identified by the unique ‘medallion’ field, compute: i) total_trips: the total number of trips begun on 8/15/2018, ii) total_passengers: the total number of passengers carried on 8/15/2018, iii) total_time_with_passengers: the total amount of time spent carrying passengers on 8/15/2018, iv) total_distance: the total distance traveled on 8/15/2018, and v) total_earnings: the total amount of money earned on 8/15/2018. The columns of your final output tibble should be: [medallion, total_trips, total_passengers, total_time_with_passengers, total_distance, total_earnings].

```{r}
options(scipen = 999)
QE <- taxi_data %>%
  group_by(medallion)%>%
  summarise(total_trips = n(), total_passengers = sum(passenger_count), total_time_with_passengers = sum(trip_time_in_secs), total_distance = sum(trip_distance), total_earnings = sum(total_amount))

head(QE)

length(unique(QE$medallion)) == nrow(QE) #a check
```

## F) For each driver, identified by his or her anonymized hack license, and for each of the 24 hours on 8/15/2018, compute: i) total_passengers_picked_up: the total number of passengers picked up during the hour, and ii) trips_started: the total number of trips started during the hour. The columns of your final output tibble should be: [hack_license, hour, total_passengers_picked_up, trips_started]. 

```{r}
QF <- taxi_data
QF$hour <- hour(QF$pickup_datetime)#get hours as its own column 
length(unique(QF$hour)) #check to see if there are 24 unique hours! 
```

We added an hour column to the dataset, by taking the hour value of pickup_datetime for each observation of QF. We then checked that there were only 24 unique values representing the 24 hours. 

```{r}
options(scipen = 999)
Combinations<-crossing(QF$hack_license,QF$hour) #each hack license will have the hours 0 -23
names(Combinations) <- c("hack_license", "hour")
QF <- right_join(QF, Combinations) #right join to keep everything in the combinations
```

```{r}
QF <- QF %>%
   group_by(hack_license,hour) %>%
  mutate(passenger_count = ifelse(is.na(passenger_count), 0, passenger_count), trip =  ifelse(!is.na(medallion), TRUE, FALSE)) %>%
summarise(total_passengers_picked_up = sum(passenger_count), trips_started = sum(trip))

head(QF, 24)
```

## G) For each driver, identified by his or her anonymized hack license, and for each of the 24 hours on 8/15/2018, compute: i) total_time_with_passengers, the total amount of time with passengers in the cab during the hour. ii) miles_with_passengers, the total number of miles traveled with passengers in the hour. For trips that cross an hour boundary, assume the driver traveled at a constant speed for the duration of the trip.iii) earnings, the total amount of money the driver earned in that hour. As with mileage, for trips that cross an hour boundary, assume drivers earn the final payment at a constant rate throughout the trip. Earnings consist of the fare plus the tip.The columns of your final output tibble should be: [hack_license, hour, total_time_with_passengers, miles_with_passengers, earnings]. 

### Create new columns for the pickup hour and dropoff hour

```{r}
QG <- taxi_data
QG$pickuphour <- hour(QG$pickup_datetime)
QG$dropoffhour <- hour(QG$dropoff_datetime)
```

### Use crossing command to join the table with a list of numbers from 0 to 23 (hours).

```{r}
hour <- 0:23
QG <- crossing(QG, hour)
nrow(QG) == 24*nrow(taxi_data) #if the taxi_data table had n rows, then the new table has 24n rows, where each row is a trip-hour
```

###  Five Cases: (1) the trip starts and ends within the hour, (2) the trip starts in the hour but ends after the hour, (3) the trip starts before the hour but ends in the hour, (4) the trip starts before the hour and ends after the hour, (5) the trip does not overlap with the hour at all.

```{r}
QG <- QG %>% 
  mutate(time_within_hour = 
           case_when(pickuphour == hour & dropoffhour == hour ~
                       as.duration(dropoff_datetime-pickup_datetime),
                     pickuphour == hour & dropoffhour > hour  ~
                       as.duration(update(pickup_datetime, 
                        hour = (hour + 1), minute = 0, second = 0) - pickup_datetime),
                     # special case ending after midnight
                     pickuphour == hour & dropoffhour < hour ~
                       as.duration(update(pickup_datetime, day = 16,
                        hour = 0, minute = 0, second = 0) - pickup_datetime),
                     pickuphour > hour & dropoffhour <= hour ~ as.duration(0),
                     
                     pickuphour < hour & dropoffhour == hour ~
                       as.duration(dropoff_datetime - update(pickup_datetime, 
                        hour = hour, minute = 0, second = 0)),
                     pickuphour < hour & dropoffhour > hour ~ as.duration(3600),
                     # missed the midnight case, but there are none anyway
                     (pickuphour < hour & dropoffhour < hour) | 
                       (pickuphour > hour & dropoffhour > hour) ~ as.duration(0)),
         
         miles_with_passengers = as.numeric(avg_speed * (time_within_hour/3600)),
         
         earnings = as.numeric((fare_amount + tip_amount) * 
                                 (time_within_hour / trip_time_in_secs))
         ) %>% 
  group_by(hack_license, hour) %>%
  summarise(total_time_with_passengers = sum(time_within_hour), miles_with_passengers = sum(miles_with_passengers), earnings = sum(earnings))  

head(QG, 24)
```

## H) Read R4DS Chapter 3. Make several plots to investigate relationships that you find interesting in the data (e.g., scatterplots, trend lines, bar charts). Feel free to examine your results from parts E, F, and G above. Describe your findings. You must make at least two plots per group member, and write at least one paragraph per group member describing your findings.

### Plot one 

```{r}
QE$DistanceGroup = cut(QE$total_distance,c(0,20,40,60,80,100,120,140,160,180,200,220,240))

ggplot(data = QE) + 
  geom_point(mapping = aes(x = total_distance, y = total_earnings, color = DistanceGroup)) + ggtitle(
    "Total Earnings + Total Distance by  Each Trip (Medallion)"
  )
```

### Plot two

```{r}
QG$MileGroup = cut(QG$miles_with_passengers, c(0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40))
ggplot(data = QG, mapping = aes(x = miles_with_passengers, y = earnings)) + 
  geom_point(mapping = aes(color = MileGroup)) +
  geom_smooth()+
  facet_wrap(~hour)+
  ggtitle( "Earnings + Miles with Passengers by Hour")
```

```{r}
ggplot(data = QG, mapping = aes(x = miles_with_passengers, y = earnings)) + 
  geom_point(mapping = aes(color = hour)) +
  scale_color_gradient(low = "red", high = "blue")+
  geom_smooth()+
  ggtitle( "Earnings by Miles with Passengers")
```
