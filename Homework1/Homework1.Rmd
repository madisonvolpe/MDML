---
title: "MDML Homework1"
author: "Madison Volpe and Andrea Hassler"
date: "9/15/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(tidyverse)
library(lubridate)
library(geosphere)
```

# 2

## A) Download 2013 NYC Taxi Data and Read Csvs

```{r, eval=FALSE}
trips <- read_csv("trip_data_8.csv")
fares <- read_csv("trip_fare_8.csv")
```

## B) Create new datasets based on 08/15/2018

```{r, eval=FALSE}
#filtering on 08/15/2018
trips <- filter(trips, as.Date(trips$pickup_datetime) == "2013-08-15")
fares <- filter(fares, as.Date(fares$pickup_datetime) == "2013-08-15")

#writing csvs
write_csv(trips, "trips_hw_1.csv")
write_csv(fares, "fares_hw_1.csv")
``` 

```{r, message=FALSE}
#read in csvs 
trips <- read_csv("trips_hw_1.csv")
fares <- read_csv("fares_hw_1.csv") 
```

## C) Clean both the ‘trips’ and ‘fares’ tibbles using your best judgment. Document your cleaning steps and assumptions.

## Trips 

### Examining trip_distance in trips tibble

```{r}
summary(trips$trip_distance)

# Check trips over 50 miles
nrow(trips[trips$trip_distance > 50, ])

# Filter between 0 and 50 miles
trips <- trips %>%
  filter(trip_distance > 0 & trip_distance < 50) %>%
  arrange(trip_distance)
```

The documentation for the dataset describes trip distance as trip distance measured by the taximeter in miles. The summary command reveals that the range of trip_distance in the dataset is from 0 miles to 5043318 miles. When we subset the trips tibble on trips that have a trip_distance greater than 50, we see that there are only 49 observations out of 473,544 that have trip_distance greater than 50 miles. Therefore, we make the decision to restrict observations in trips to trip_distances greater than 0, but less than 50 miles. 

```{r}
summary(trips$trip_distance)
```

We now see that the range of our trip_distance variable in the trips tibble is from .01 miles to 48 miles, which seems more reasonable. 

### Examining passenger_count

```{r}
summary(trips$passenger_count)

# Filter out 0 counts
trips <- trips %>%
  filter(passenger_count > 0) 

# New summary
summary(trips$passenger_count)
```

According to NYC.gov, the legal amount of passengers for taxis in NYC is between four or five depending on the size of the vehicle. Also small children are allowed to sit on laps in the back seat, therefore a max of six passengers is justifiable. 

### Examining trip_time_in_secs in trips tibble

```{r}
summary(trips$trip_time_in_secs)

# Check if trip_time_in_secs matches difference
trips <- mutate(trips, trip_time_in_secs_2 = as.duration(dropoff_datetime - pickup_datetime))
all(trips$trip_time_in_secs == as.integer(trips$trip_time_in_secs_2))
```

The documentation for the dataset describes the trip_time_in_secs field as the trip time measured in seconds by the taximeter. However, it also states that sometimes this variable is recorded in minutes. Therefore, they note that this variable is unreliable. They state that a more reliable measure of trip time is obtained by subtracting pickup_datetime from dropoff_datetime.

The initial summary of trip_time_in_secs shows that the range for this value is from -10 to 22080. We then compute the more "accurate" measure of trip time by subtracting pickup_datetime from dropoff_datetime, and we name this variable trip_time_in_secs_2. We use the all command to check if the two columns, trip_time_in_secs and trip_time_in_secs2, are the same for all values. The FALSE informs us that they are not. 

```{r}
# Check difference in measures
trips <- mutate(trips, diff = abs(dseconds(trip_time_in_secs) - trip_time_in_secs_2))
trips <- arrange(trips, desc(diff)) 
head(trips$diff, 20)

# Filter to only have trips that differ in these two variables by less than 1 min
trips <- filter(trips, diff < dminutes(1))
head(trips$diff, 20) 
range(trips$diff) #difference ranging from 0 to 57 seconds! 

# Drop irrelevant columns
trips <- select(trips, -trip_time_in_secs_2, -diff) 

summary(trips$trip_time_in_secs)

# Filter to remove negative trip times that are less than 60 seconds (1 min)
trips <- trips %>%
  filter(trip_time_in_secs >= 60 )

summary(trips$trip_time_in_secs)
```

Next, we create another new variable, diff, which takes the difference from the trip_time_in_secs variable, native to the dataset and sometimes wrong, and trip_time_in_secs2 variable, constructed as a more valid measure of trip time. We then filter to include only the trips that differ between these two measures by less than one minute. 

After doing this, the summary of trip_time_in_secs still reveals unlikely numbers, such as -10 second trip time.The max value of 22,080 seconds, or 6.1 hours, seems likely. The mean of 13.8 mins seems likely as well. Ultimately, we decide to keep trips that only have trip_time_in_secs greater than or equal to 60 seconds (1 minute). This was checked by running summary on trip_time_in_secs to reveal the min value of 60. 

### Examining unrealistic speeds and distances

The dataset documentation mentions cases of unrealistic speeds and distances in the dataset. First, we check for unrealistic speeds by converting trip time from seconds to hours and then calculate average speed by dividing trip distance by trip time in hours.

```{r}
# Add average speed
trips <- mutate(trips, avg_speed = trip_distance/(trip_time_in_secs/3600))
# Top average speeds
head(sort(trips$avg_speed, decreasing = T))
# Filter out trip speeds greater than 100mph
trips <- filter(trips, avg_speed < 100)
summary(trips$avg_speed)
```
We filter out average speeds over 100mph. We leave the very low average trip speeds, since these make sense under heavy traffic conditions. Next, we check unrealistic distances, defined as trip distances that are shorter than the straight-line distance between the pickup location and dropoff location, given in latitude and longitude coordinates. For this, we wanted to use the geoshere package and calculate distance using the Haversine formula. Unfortunately, this process was too memory-intensive to compute for this many observations given limited computing power. The code below shows the removal of impossible longitude and latitude values, as well as the code we would have used to remove unrealistic distances.

```{r}
# Check number of unrealistic longitude and latitude values
nrow(trips[trips$pickup_longitude < -90 | trips$pickup_longitude > 90, ])
nrow(trips[trips$dropoff_longitude < -90 | trips$dropoff_longitude > 90, ])
nrow(trips[trips$pickup_latitude < -180 | trips$pickup_latitude > 180, ])
nrow(trips[trips$dropoff_latitude < -180 | trips$dropoff_latitude > 180, ])

# Filter out unrealistic coordinates
trips <- filter(trips, 
                pickup_longitude >= -90 & pickup_longitude <= 90,
                dropoff_longitude >= -90 & dropoff_longitude <= 90,
                pickup_latitude >= -180 & pickup_latitude <= 180,
                dropoff_latitude >= -180 & dropoff_latitude <=180)

# Compute straight-line distances in miles
# trips <- mutate(trips, 
#                 straight_dist = distm(x = cbind(pickup_longitude, pickup_latitude),
#                                       y = cbind(dropoff_longitude, dropoff_latitude), 
#                                       fun = distHaversine))
```

## Fares

### Examining payment_type 

```{r}
# Examine the different values for payment type 
unique(fares$payment_type)

# Filter only on cash (CSH) and and credit (CRD) payment types 
fares <- fares %>%
  filter(payment_type %in% c("CSH", "CRD"))

unique(fares$payment_type)
```

We decided to examine payment_type and we limited payment_type to only cash and credit payments. In the dataset documentation, these are listed as the only possibilities for the variable payment_type.

### Examining fare_amount 

```{r}
# Summary on fare_amount 
summary(fares$fare_amount)

# Examining outliers, negative values, and values greater than 500
nrow(fares[fares$fare_amount < 0, ])
sum(fares$total_amount[fares$fare_amount < 0] < 0)
fares$fare_amount[fares$fare_amount > 500]

# Filter for fare amounts greater than 2.50 
fares <- fares %>%
  filter(fare_amount >= 2.50)

# Reobserving fare_amount
summary(fares$fare_amount)
```

We see that fare_amount, which represents the meter fare in USD, has a range of -460.00 dollars to 955.00 dollars.  We further find that there are 126 observations with negative values for fare_amount, and we can see that total_amount is also negative for these observations. Furthermore, we observe that there are 4 observations with fare_amount greater than 500 dollars. We decided to drop any fare_amount less than 2.50 because 2.50 is the minimum initial charge listed by NYC Taxi & Limousine Commission, but we keep the fare_amount values over 500 dollars, which may not be unrealistic for longer trips out of the city.

### Examining other charges and amounts

```{r}
summary(fares$surcharge)
summary(fares$mta_tax)
summary(fares$tip_amount)
summary(fares$tolls_amount)
summary(fares$total_amount)

# Check that total_amount is true total
fares <- mutate(fares, calc_total = 
                  fare_amount + surcharge + mta_tax + tip_amount + tolls_amount)
all(fares$total_amount == fares$calc_total)
fares <- mutate(fares, diff = round(abs(total_amount - calc_total), 3))

# Remove differences larger than $1
head(sort(fares$diff, decreasing = T))
nrow(fares[fares$diff > 0, ])
fares <- filter(fares, diff == 0)
summary(fares$diff)

# Remove extra variables
fares <- select(fares, -calc_total, -diff)
```

We examine the remaining variables, which all look reasonable. We then remove any observations whose total_amount does not match the calculated total from the variables (18 cases).

## D) [10 pts] Join the ‘trips’ and ‘fares’ tibbles together into a tibble called ‘taxi_data.’ This joined tibble should have one row for each trip, and should have complete fare information (you may have to deal with duplicates and missing values that arise from the join).

### Initial Cleaning 

```{r}
trips$UID <- paste(trips$medallion, trips$hack_license, trips$pickup_datetime, sep = "_")
fares$UID <- paste(fares$medallion, fares$hack_license, fares$pickup_datetime, sep = "_")

trips %>% count(UID)%>%filter(n>1) #works for trips 
length(unique(trips$UID)) == nrow(trips) #also see if true 

fares %>% count(UID)%>%filter(n>1) #does not work for fares 
length(unique(fares$UID)) == nrow(fares) #we can see that there are duplicates! 

trips <- distinct(trips)
fares <- distinct(fares)
```

What we are observing so far with all these preliminary checks is that the unique identifier in trips does indeed correspond to one trip. However, the unique identifier for fares may correspond to two or more trips. The directions ask us to have one row for each trip. Likewise, we also need to have complete fare information. In this case, our final tibble should have 457,033 rows to correspond to each unique trip from the trips tibble. 

```{r}
fares$pickup_datetime <- as.POSIXct(fares$pickup_datetime)
taxi_data <- trips %>% left_join(fares)
taxi_data %>% count(UID)%>%filter(n>1) #works for trips 
``` 

An initial left join to create taxi_data leaves us with 457,113. This is more rows than the initial trips dataset of 457,033. With the trips dataset, we had already found out that each UID accounted for one trip. When reusing the code from above, we see that there are 80 rows that are duplicated. 

```{r}
# let's use anti join to see if there are rows in trips that don't have corresponding fares associated
trips %>% anti_join(fares)
```

```{r}
# now let's get rid of those "duplicate" rows in the fares tibble by keeping the fare with highest total amount
fares <- fares %>% arrange(desc(total_amount)) %>% distinct(medallion, hack_license, pickup_datetime, .keep_all = TRUE)
```

```{r}
taxi_data <- inner_join(trips,fares)

nrow(taxi_data) + nrow(trips %>% anti_join(fares)) == nrow(trips) # we now see that the number of rows resulting from the inner joing plus the nrow  from the anti join does equal the nrow of trips 
```

```{r}
length(unique(taxi_data$UID)) == nrow(taxi_data) #one row for each trip test 
sum(is.na(taxi_data[,16:22])) #complete fare information for each trip test. 
```

We can see that the number of unique UIDs in taxi_data is equal to the number of rows in taxi_data implying that each row represents only one trip. We can also see that the result of our joining also leads to complete fare information for each trip.

## E) For each taxicab, identified by the unique ‘medallion’ field, compute: i) total_trips: the total number of trips begun on 8/15/2018, ii) total_passengers: the total number of passengers carried on 8/15/2018, iii) total_time_with_passengers: the total amount of time spent carrying passengers on 8/15/2018, iv) total_distance: the total distance traveled on 8/15/2018, and v) total_earnings: the total amount of money earned on 8/15/2018. The columns of your final output tibble should be: [medallion, total_trips, total_passengers, total_time_with_passengers, total_distance, total_earnings].

```{r}
QE <- taxi_data %>%
  group_by(medallion)%>%
  transmute(total_trips = n(), total_passengers = sum(passenger_count), total_time_with_passengers = sum(trip_time_in_secs), total_distance = sum(trip_distance), total_earnings = sum(total_amount))

head(QE)
```

## F) For each driver, identified by his or her anonymized hack license, and for each of the 24 hours on 8/15/2018, compute: i) total_passengers_picked_up: the total number of passengers picked up during the hour, and ii) trips_started: the total number of trips started during the hour. The columns of your final output tibble should be: [hack_license, hour, total_passengers_picked_up, trips_started]. 

```{r}
QF <- taxi_data
QF$hour <- hour(QF$pickup_datetime)#get hours as its own column 
length(unique(QF$hour)) #check to see if there are 24 unique hours! 
```

We added an hour column to the taxi dataset, by taking the hour value of pickup_datetime for each observation of QF. We then checked that there were only 24 unique values representing the 24 hours. 

```{r}
options(scipen = 999)
Combinations<-crossing(QF$hack_license,QF$hour)
names(Combinations) <- c("hack_license", "hour")
QF <- right_join(QF,Combinations)
```

```{r}
QF <- QF %>%
   group_by(hack_license,hour) %>%
  mutate(passenger_count = ifelse(is.na(passenger_count), 0, passenger_count), trip =  ifelse(!is.na(medallion), TRUE, FALSE)) %>%
summarise(total_passengers_picked_up = sum(passenger_count), trips_started = sum(trip))

head(QF, 24)
```


## G) For each driver, identified by his or her anonymized hack license, and for each of the 24 hours on 8/15/2018, compute: i) total_time_with_passengers, the total amount of time with passengers in the cab during the hour. ii) miles_with_passengers, the total number of miles traveled with passengers in the hour. For trips that cross an hour boundary, assume the driver traveled at a constant speed for the duration of the trip.iii) earnings, the total amount of money the driver earned in that hour. As with mileage, for trips that cross an hour boundary, assume drivers earn the final payment at a constant rate throughout the trip. Earnings consist of the fare plus the tip.The columns of your final output tibble should be: [hack_license, hour, total_time_with_passengers, miles_with_passengers, earnings]. 

## preliminary work 


```{r}
# Check latest dropoff dates and times
taxi_data %>% arrange(desc(dropoff_datetime)) %>% select(dropoff_datetime) %>% head(10)

# Sample of 1000 hack licenses to test on, including trip over two hours
set.seed(888)
sample_taxi <- filter(taxi_data, hack_license %in% sample(taxi_data$hack_license, 1000))
sum(sample_taxi$trip_time_in_secs > 7200, na.rm = T)


QG <- sample_taxi %>%
  # Subset to only needed columns
  select(hack_license, pickup_datetime, dropoff_datetime, trip_time_in_secs, 
         trip_distance, avg_speed, fare_amount, tip_amount, hour) %>%
  # Add end time column with 24 instead of dealing with 0s on second day
  mutate(end_hour = 
           case_when(date(dropoff_datetime) == "2013-08-15" ~ hour(dropoff_datetime),
                     date(dropoff_datetime) == "2013-08-16" ~ as.integer(24)))

  # Apply to observations without NAs for end_hour;
  # This should capture all trips starting in hour until hour end
QG <- QG %>%  group_by(hack_license, hour) %>%
  mutate(total_time_with_passengers = 
           case_when(hour == end_hour ~ as.numeric(trip_time_in_secs),
                     hour < end_hour ~ as.numeric(as.duration(update(pickup_datetime, 
                          hour = (hour + 1), minute = 0, second = 0) - pickup_datetime))),
                              
         miles_with_passengers = 
           case_when(hour == end_hour ~ as.numeric(trip_distance),
                     hour < end_hour ~ 
                       as.numeric(avg_speed * (total_time_with_passengers/3600))),
         
         earnings = 
           case_when(hour == end_hour ~ as.numeric(sum(fare_amount, tip_amount)),
                     hour < end_hour ~ as.numeric((fare_amount + tip_amount) *
                       (total_time_with_passengers/trip_time_in_secs))))

##### Works up until here

# Capture trips that cover full hour (start in previous, end in later)
QG <- QG %>% group_by(hack_license) 
  for (i in 1:length(QG$hour)) {
    if (is.na(QG$end_hour[i]) == T) 
  }


# Capture trips that start in previous, end in current


# Append tibbles and summarise

```

```{r}
taxi_data$hourrange <- paste(hour(taxi_data$pickup_datetime), hour(taxi_data$dropoff_datetime), sep = "-")
taxi_data$differencetime = difftime(taxi_data$dropoff_datetime,taxi_data$pickup_datetime)
```

```{r}
options(scipen = 999)

G <- taxi_data %>%
  group_by(hack_license, hour) %>%
  mutate(trip_time_in_secs = ifelse(trip_time_in_secs > 3600, 3600, trip_time_in_secs))%>%
  mutate(avg_speed = ifelse(trip_time_in_secs>3600, (trip_distance/3600)*3600,avg_speed)) %>%
  summarise(count = n())



  summarise(total_time_with_passengers = sum(trip_time_in_secs), miles_with_passengers = sum(trip_distance), earnings = sum(fare_amount, tip_amount))
```

NEED TO FIX THIS !

## My attempt - w. Dorota's hints

```{r}
# Five Cases
# 1. trip starts and ends in same hour
      # To ID: hour == hour_end
      # time = time in secs; miles = trip dist; earnings = fare + tip
# 2. trip starts this hour, but ends in different hour same day
      # To ID: hour < hour_end
      # time = (hour + 1) - start time; miles = avg_spd * (time/3600);
      # earnings = (fare + tip) * (time/trip time)
#   >special case: starts this hour and ends hour 0 of next day
      # To ID: hour > hour_end
      # time = (hour + 1) - start time; miles = avg_spd * (time/3600);
      # earnings = (fare + tip) * (time/trip time)
# 3. trip started in previous hour and ends this hour
      # To ID: if hour(dropoff) for previous hour == current hour, then
      # time = dropoff - (hour-1); miles = avg_spd * (time/3600);
      # earnings = (fare + tip) * (time/trip time)
# 4. trip started in some previous hour and ends in some future hour, and includes this hour
      # To ID: 
      # time = 3600; miles = avg_speed; earnings = (fare + tip) * (3600/trip time)
# 5.  hour with no trips/parts of trips
      # Put in zeros for all
```

#Create new columns for the pickup hour and dropoff hour

```{r}
QG <- taxi_data
QG$pickuphour <- hour(QG$pickup_datetime)
QG$dropoffhour <- hour(QG$dropoff_datetime)

QG <-QG %>% 
  mutate(dropoffhour = 
           case_when(date(dropoff_datetime) == "2013-08-15" ~ hour(dropoff_datetime),
                     date(dropoff_datetime) == "2013-08-16" ~ as.integer(24)))
```

#Use crossing command to join the table with a list of numbers from 0 to 23 (hours).

```{r}
hour <- 0:23
QG <- crossing(QG, hour)
nrow(QG) == 24*nrow(taxi_data) #if the taxi_data table had n rows, then the new table has 24n rows, where each row is a trip-hour
```

# Next, I created a new variable, time_within_hour, that for each trip-hour, records the length of time of that trip in that hour as a duration (from lubridate). The variable time_within_hour is constructed by considering five cases using the case_when() command: (1) the trip starts and ends within the hour, (2) the trip starts in the hour but ends after the hour, (3) the trip starts before the hour but ends in the hour, (4) the trip starts before the hour and ends after the hour, (5) the trip does not overlap with the hour at all. Finally, group by hack license and hour, and summarize.

```{r}
QG %>%
  mutate(time_within_hour = 
           case_when(pickuphour == hour & dropoffhour == hour ~ as.duration(dropoff_datetime-pickup_datetime),
                     pickuphour == hour & dropoffhour > hour  ~ as.duration(),
                     pickuphour < hour & dropoffhour == hour ~ ,
                     pickuphour < hour & dropoffhour > hour ~, 
                     pickuphour < hour & dropoffhour < hour | pickuphour > hour & dropoffhour > hour ~ 0)) 
```

